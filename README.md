## **ENGLISH** 吼

![project_cover](images/project_cover.jpg)

This project implements an automated system to collect, store, and manage weather data using the OpenWeatherMap API, MongoDB, and Apache Airflow. It is designed to provide a robust solution for efficiently and systematically gathering climate information, with possibilities for analysis and visualization.
This repository aims to demonstrate how MongoDB can be used to store and query weather data, complemented by Apache Airflow for process automation. It serves as an educational or demonstrative project and as a foundation for customized solutions.

---

## **How It Works 锔**

### **The Pipeline:**
- **Execution**:  
   The Airflow DAG (`weather_dag.py`) runs on a schedule or can be manually triggered via the Airflow interface.

- **Data Collection**:  
   Weather data is fetched from the OpenWeatherMap API, capturing information such as temperature, humidity, and weather conditions for a specified city.

- **Processing & Storage**:  
   The collected data is validated and stored in MongoDB under the `weather` collection within the `weatherDB` database.

### **Outputs:**
- **Database Entry**:  
   All weather data is stored in MongoDB, enabling easy querying and analysis.

---

## **Screenshots ** 

![MongoDB Interface](images/screenshots/mongoDB_interface.png)
MongoDB Interface
This screenshot shows how weather data is stored in the weatherDB database, specifically in the weather collection. Key fields such as city, temperature, humidity, and others are displayed, confirming that the information was successfully collected and saved.

![Airflow Terminal - Scheduler](images/screenshots/airflow_terminal_1.png)
Airflow Terminal (Scheduler)
This screenshot demonstrates the execution of the airflow scheduler command, which is responsible for initiating workflows defined in the DAGs. The Scheduler ensures that tasks are executed as per the defined schedule.

![Airflow Terminal - Webserver](images/screenshots/airflow_terminal_2.png)
Airflow Terminal (Webserver)
This image shows the execution of the airflow webserver command, which launches Airflows web interface. From this interface, you can manage DAGs, monitor tasks, and view their status in real time.

![Airflow Interface](images/screenshots/airflow_interface.png)
Airflow Interface
This screenshot displays the activated DAG from the Airflow interface. The workflow graph and task status confirm that the entire system is functioning correctly.

---
## **SPANISH** 吼

Este proyecto implementa un sistema automatizado para recopilar, almacenar y gestionar datos meteorol贸gicos utilizando la API de OpenWeatherMap, MongoDB y Apache Airflow. Est谩 dise帽ado para ofrecer una soluci贸n robusta que permita recolectar informaci贸n del clima de manera eficiente y programada, con posibilidades de an谩lisis y visualizaci贸n.
Este repositorio est谩 destinado a mostrar c贸mo MongoDB puede ser utilizado para almacenar y consultar datos meteorol贸gicos, complementado con Apache Airflow para la automatizaci贸n de procesos. Es ideal como proyecto educativo, demostrativo o como base para soluciones personalizadas.

---

C贸mo Funciona 锔
El Proceso:
- Ejecuci贸n:
El DAG de Airflow (weather_dag.py) se ejecuta de forma programada o puede ser activado manualmente desde la interfaz de Airflow.
- Obtenci贸n de Datos:
Se recopilan datos meteorol贸gicos desde la API de OpenWeatherMap, como la temperatura, la humedad y las condiciones clim谩ticas de una ciudad espec铆fica.
- Procesamiento y Almacenamiento:
Los datos recopilados son validados y almacenados en MongoDB dentro de la colecci贸n weather, perteneciente a la base de datos weatherDB.

Resultados:
- Entrada en la Base de Datos:
Todos los datos meteorol贸gicos procesados se almacenan en MongoDB, lo que permite consultas y an谩lisis sencillos.

---

## **Capturas ** 

![MongoDB Interface](images/screenshots/mongoDB_interface.png)
MongoDB Interface
En esta captura, se muestra c贸mo los datos meteorol贸gicos se almacenan en la base de datos weatherDB, espec铆ficamente en la colecci贸n weather. Este ejemplo destaca las claves como city, temperature, humidity, entre otras, demostrando que la informaci贸n fue recopilada correctamente.

![Airflow Terminal - Scheduler](images/screenshots/airflow_terminal_1.png)
Airflow Terminal (Scheduler)
Aqu铆 se presenta la ejecuci贸n del comando airflow scheduler, responsable de iniciar los flujos de trabajo definidos en los DAGs. El Scheduler asegura que las tareas se ejecuten de acuerdo con la programaci贸n establecida.

![Airflow Terminal - Webserver](images/screenshots/airflow_terminal_2.png)
Airflow Terminal (Webserver)
Esta captura muestra la ejecuci贸n del comando airflow webserver, que inicia la interfaz web de Airflow. Desde esta interfaz, se pueden gestionar los DAGs, monitorear las tareas y visualizar su estado en tiempo real.

![Airflow Interface](images/screenshots/airflow_interface.png)
Airflow Interface
En esta captura de pantalla, se muestra el DAG activado desde la interfaz de Airflow. El gr谩fico del flujo de trabajo y el estado de las tareas permiten confirmar que todo el sistema est谩 funcionandocorrectamente.
